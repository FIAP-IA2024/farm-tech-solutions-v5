{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análise de Produtividade de Culturas\n",
    "\n",
    "Este notebook realiza uma análise completa de dados de produtividade agrícola, incluindo:\n",
    "- Análise Exploratória de Dados (EDA)\n",
    "- Análise de Correlação\n",
    "- Clustering com K-Means\n",
    "- Identificação de Outliers\n",
    "- Visualizações 2D e 3D dos Clusters\n",
    "\n",
    "O objetivo é identificar padrões e insights que possam ajudar a otimizar a produtividade agrícola."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Configuração e Importação de Bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importação das bibliotecas necessárias\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "# Configurações de visualização\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette('viridis')\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 12\n",
    "\n",
    "# Configuração para exibir todas as colunas do DataFrame\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# Configuração do diretório de imagens\n",
    "IMAGES_DIR = os.path.join('..', 'images')\n",
    "os.makedirs(IMAGES_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Carregamento e Exploração dos Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file_path):\n",
    "    \"\"\"\n",
    "    Carrega os dados do arquivo CSV e retorna um DataFrame pandas.\n",
    "    \n",
    "    Args:\n",
    "        file_path (str): Caminho para o arquivo CSV\n",
    "        \n",
    "    Returns:\n",
    "        pandas.DataFrame: DataFrame com os dados carregados\n",
    "    \"\"\"\n",
    "    try:\n",
    "        df = pd.read_csv(file_path)\n",
    "        print(f\"Dados carregados com sucesso: {file_path}\")\n",
    "        print(f\"Dimensões do dataset: {df.shape[0]} linhas x {df.shape[1]} colunas\")\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao carregar os dados: {e}\")\n",
    "        return None\n",
    "\n",
    "# Carregar os dados\n",
    "file_path = os.path.join('..', 'data', 'crop_yield.csv')\n",
    "df = load_data(file_path)\n",
    "\n",
    "# Exibir as primeiras linhas do DataFrame\n",
    "display(Markdown(\"### Primeiras linhas do dataset:\"))\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Informações do Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_dataset_info(df):\n",
    "    \"\"\"\n",
    "    Exibe informações sobre o dataset.\n",
    "    \n",
    "    Args:\n",
    "        df (pandas.DataFrame): DataFrame a ser analisado\n",
    "    \"\"\"\n",
    "    display(Markdown(\"### Informações do Dataset:\"))\n",
    "    display(df.info())\n",
    "    \n",
    "    display(Markdown(\"### Estatísticas Descritivas:\"))\n",
    "    display(df.describe())\n",
    "    \n",
    "    display(Markdown(\"### Tipos de Dados:\"))\n",
    "    display(pd.DataFrame(df.dtypes, columns=['Tipo de Dado']))\n",
    "    \n",
    "    # Verificar valores únicos para colunas categóricas\n",
    "    categorical_cols = df.select_dtypes(include=['object']).columns\n",
    "    if len(categorical_cols) > 0:\n",
    "        display(Markdown(\"### Valores Únicos em Colunas Categóricas:\"))\n",
    "        for col in categorical_cols:\n",
    "            print(f\"\\n{col}: {df[col].nunique()} valores únicos\")\n",
    "            display(df[col].value_counts())\n",
    "\n",
    "# Exibir informações do dataset\n",
    "display_dataset_info(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Análise de Valores Ausentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_missing_values(df):\n",
    "    \"\"\"\n",
    "    Analisa valores ausentes no DataFrame.\n",
    "    \n",
    "    Args:\n",
    "        df (pandas.DataFrame): DataFrame a ser analisado\n",
    "    \"\"\"\n",
    "    display(Markdown(\"### Análise de Valores Ausentes:\"))\n",
    "    \n",
    "    # Contagem de valores ausentes por coluna\n",
    "    missing_values = df.isnull().sum()\n",
    "    missing_percent = (missing_values / len(df)) * 100\n",
    "    \n",
    "    missing_df = pd.DataFrame({\n",
    "        'Valores Ausentes': missing_values,\n",
    "        'Percentual (%)': missing_percent\n",
    "    })\n",
    "    \n",
    "    display(missing_df)\n",
    "    \n",
    "    # Visualizar valores ausentes\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.heatmap(df.isnull(), cbar=False, yticklabels=False, cmap='viridis')\n",
    "    plt.title('Mapa de Valores Ausentes')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(IMAGES_DIR, 'missing_values_heatmap.png'))\n",
    "    plt.show()\n",
    "    \n",
    "    # Se existirem valores ausentes, sugerir estratégias de tratamento\n",
    "    if missing_values.sum() > 0:\n",
    "        display(Markdown(\"### Estratégias de Tratamento de Valores Ausentes:\"))\n",
    "        for col in df.columns[missing_values > 0]:\n",
    "            print(f\"\\nColuna: {col} - {missing_percent[col]:.2f}% ausentes\")\n",
    "            if missing_percent[col] < 5:\n",
    "                print(\"  Recomendação: Remover linhas ou imputar com média/mediana\")\n",
    "            elif missing_percent[col] < 30:\n",
    "                print(\"  Recomendação: Imputar valores usando técnicas avançadas (KNN, modelos preditivos)\")\n",
    "            else:\n",
    "                print(\"  Recomendação: Considerar remover a coluna ou investigar a causa dos valores ausentes\")\n",
    "\n",
    "# Analisar valores ausentes\n",
    "analyze_missing_values(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Tratamento de Valores Ausentes (se necessário)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_missing_values(df):\n",
    "    \"\"\"\n",
    "    Trata valores ausentes no DataFrame.\n",
    "    \n",
    "    Args:\n",
    "        df (pandas.DataFrame): DataFrame com valores ausentes\n",
    "        \n",
    "    Returns:\n",
    "        pandas.DataFrame: DataFrame com valores ausentes tratados\n",
    "    \"\"\"\n",
    "    # Verificar se existem valores ausentes\n",
    "    if df.isnull().sum().sum() == 0:\n",
    "        print(\"Não há valores ausentes para tratar.\")\n",
    "        return df\n",
    "    \n",
    "    # Criar uma cópia do DataFrame para não modificar o original\n",
    "    df_clean = df.copy()\n",
    "    \n",
    "    # Para cada coluna com valores ausentes\n",
    "    for col in df.columns[df.isnull().sum() > 0]:\n",
    "        # Se for coluna numérica, imputar com a mediana\n",
    "        if df[col].dtype in ['int64', 'float64']:\n",
    "            median_value = df[col].median()\n",
    "            df_clean[col].fillna(median_value, inplace=True)\n",
    "            print(f\"Valores ausentes em '{col}' preenchidos com a mediana: {median_value}\")\n",
    "        # Se for coluna categórica, imputar com o valor mais frequente\n",
    "        else:\n",
    "            mode_value = df[col].mode()[0]\n",
    "            df_clean[col].fillna(mode_value, inplace=True)\n",
    "            print(f\"Valores ausentes em '{col}' preenchidos com o valor mais frequente: {mode_value}\")\n",
    "    \n",
    "    # Verificar se todos os valores ausentes foram tratados\n",
    "    if df_clean.isnull().sum().sum() == 0:\n",
    "        print(\"\\nTodos os valores ausentes foram tratados com sucesso!\")\n",
    "    else:\n",
    "        print(\"\\nAtenção: Ainda existem valores ausentes no DataFrame.\")\n",
    "    \n",
    "    return df_clean\n",
    "\n",
    "# Tratar valores ausentes\n",
    "df_clean = handle_missing_values(df)\n",
    "\n",
    "# Verificar se ainda existem valores ausentes\n",
    "print(f\"\\nValores ausentes restantes: {df_clean.isnull().sum().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Análise Exploratória de Dados (EDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Análise da Distribuição dos Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_data_distribution(df):\n",
    "    \"\"\"\n",
    "    Analisa a distribuição das variáveis numéricas no DataFrame.\n",
    "    \n",
    "    Args:\n",
    "        df (pandas.DataFrame): DataFrame a ser analisado\n",
    "    \"\"\"\n",
    "    display(Markdown(\"### Distribuição das Variáveis Numéricas:\"))\n",
    "    \n",
    "    # Selecionar apenas colunas numéricas\n",
    "    numeric_cols = df.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "    \n",
    "    # Criar histogramas para cada variável numérica\n",
    "    n_cols = 2  # Número de colunas no grid de plots\n",
    "    n_rows = (len(numeric_cols) + n_cols - 1) // n_cols  # Número de linhas necessárias\n",
    "    \n",
    "    plt.figure(figsize=(15, n_rows * 5))\n",
    "    \n",
    "    for i, col in enumerate(numeric_cols):\n",
    "        plt.subplot(n_rows, n_cols, i + 1)\n",
    "        \n",
    "        # Histograma com KDE\n",
    "        sns.histplot(df[col], kde=True, color='skyblue')\n",
    "        \n",
    "        # Adicionar linha vertical para média e mediana\n",
    "        plt.axvline(df[col].mean(), color='red', linestyle='--', label=f'Média: {df[col].mean():.2f}')\n",
    "        plt.axvline(df[col].median(), color='green', linestyle='-.', label=f'Mediana: {df[col].median():.2f}')\n",
    "        \n",
    "        plt.title(f'Distribuição de {col}')\n",
    "        plt.xlabel(col)\n",
    "        plt.ylabel('Frequência')\n",
    "        plt.legend()\n",
    "        plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(IMAGES_DIR, 'numeric_distributions.png'))\n",
    "    plt.show()\n",
    "    \n",
    "    # Criar boxplots para identificar outliers\n",
    "    plt.figure(figsize=(15, n_rows * 4))\n",
    "    \n",
    "    for i, col in enumerate(numeric_cols):\n",
    "        plt.subplot(n_rows, n_cols, i + 1)\n",
    "        \n",
    "        # Boxplot\n",
    "        sns.boxplot(x=df[col], color='skyblue')\n",
    "        \n",
    "        plt.title(f'Boxplot de {col}')\n",
    "        plt.xlabel(col)\n",
    "        plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(IMAGES_DIR, 'numeric_boxplots.png'))\n",
    "    plt.show()\n",
    "    \n",
    "    # Se houver variáveis categóricas, criar gráficos de contagem\n",
    "    categorical_cols = df.select_dtypes(include=['object']).columns.tolist()\n",
    "    \n",
    "    if len(categorical_cols) > 0:\n",
    "        display(Markdown(\"### Distribuição das Variáveis Categóricas:\"))\n",
    "        \n",
    "        n_rows_cat = (len(categorical_cols) + n_cols - 1) // n_cols\n",
    "        plt.figure(figsize=(15, n_rows_cat * 5))\n",
    "        \n",
    "        for i, col in enumerate(categorical_cols):\n",
    "            plt.subplot(n_rows_cat, n_cols, i + 1)\n",
    "            \n",
    "            # Gráfico de contagem\n",
    "            value_counts = df[col].value_counts().sort_values(ascending=False)\n",
    "            sns.barplot(x=value_counts.index, y=value_counts.values, palette='viridis')\n",
    "            \n",
    "            plt.title(f'Contagem de {col}')\n",
    "            plt.xlabel(col)\n",
    "            plt.ylabel('Contagem')\n",
    "            plt.xticks(rotation=45)\n",
    "            plt.grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(IMAGES_DIR, 'categorical_distributions.png'))\n",
    "        plt.show()\n",
    "\n",
    "# Analisar distribuição dos dados\n",
    "analyze_data_distribution(df_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Análise de Correlação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_correlations(df):\n",
    "    \"\"\"\n",
    "    Analisa correlações entre variáveis numéricas no DataFrame.\n",
    "    \n",
    "    Args:\n",
    "        df (pandas.DataFrame): DataFrame a ser analisado\n",
    "    \"\"\"\n",
    "    display(Markdown(\"### Matriz de Correlação:\"))\n",
    "    \n",
    "    # Selecionar apenas colunas numéricas\n",
    "    numeric_df = df.select_dtypes(include=['int64', 'float64'])\n",
    "    \n",
    "    # Calcular matriz de correlação\n",
    "    corr_matrix = numeric_df.corr()\n",
    "    \n",
    "    # Exibir matriz de correlação\n",
    "    display(corr_matrix)\n",
    "    \n",
    "    # Visualizar matriz de correlação como heatmap\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    mask = np.triu(np.ones_like(corr_matrix, dtype=bool))  # Máscara para exibir apenas o triângulo inferior\n",
    "    cmap = sns.diverging_palette(230, 20, as_cmap=True)\n",
    "    \n",
    "    sns.heatmap(corr_matrix, mask=mask, cmap=cmap, vmax=1, vmin=-1, center=0,\n",
    "                square=True, linewidths=.5, annot=True, fmt='.2f', cbar_kws={\"shrink\": .5})\n",
    "    \n",
    "    plt.title('Matriz de Correlação')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(IMAGES_DIR, 'correlation_matrix.png'))\n",
    "    plt.show()\n",
    "    \n",
    "    # Identificar correlações fortes (positivas e negativas)\n",
    "    display(Markdown(\"### Correlações Significativas:\"))\n",
    "    \n",
    "    # Converter a matriz de correlação em um DataFrame de pares\n",
    "    corr_pairs = corr_matrix.unstack().reset_index()\n",
    "    corr_pairs.columns = ['Variável 1', 'Variável 2', 'Correlação']\n",
    "    \n",
    "    # Remover autocorrelações e duplicatas\n",
    "    corr_pairs = corr_pairs[corr_pairs['Variável 1'] != corr_pairs['Variável 2']]\n",
    "    corr_pairs = corr_pairs.drop_duplicates(['Correlação'])\n",
    "    \n",
    "    # Ordenar por valor absoluto da correlação (decrescente)\n",
    "    corr_pairs['Abs_Correlação'] = corr_pairs['Correlação'].abs()\n",
    "    corr_pairs = corr_pairs.sort_values('Abs_Correlação', ascending=False).drop('Abs_Correlação', axis=1)\n",
    "    \n",
    "    # Exibir correlações significativas (|r| > 0.5)\n",
    "    significant_corr = corr_pairs[corr_pairs['Correlação'].abs() > 0.5]\n",
    "    \n",
    "    if len(significant_corr) > 0:\n",
    "        display(significant_corr)\n",
    "        \n",
    "        # Visualizar pares com correlações mais fortes\n",
    "        display(Markdown(\"### Visualização de Pares com Correlações Significativas:\"))\n",
    "        \n",
    "        # Limitar a 5 pares mais correlacionados para não sobrecarregar\n",
    "        top_pairs = significant_corr.head(5)\n",
    "        \n",
    "        for _, row in top_pairs.iterrows():\n",
    "            var1, var2, corr = row['Variável 1'], row['Variável 2'], row['Correlação']\n",
    "            \n",
    "            plt.figure(figsize=(10, 6))\n",
    "            sns.scatterplot(x=df[var1], y=df[var2], alpha=0.7)\n",
    "            \n",
    "            # Adicionar linha de tendência\n",
    "            sns.regplot(x=df[var1], y=df[var2], scatter=False, color='red')\n",
    "            \n",
    "            plt.title(f'Correlação entre {var1} e {var2}: {corr:.2f}')\n",
    "            plt.xlabel(var1)\n",
    "            plt.ylabel(var2)\n",
    "            plt.grid(True, alpha=0.3)\n",
    "            plt.savefig(os.path.join(IMAGES_DIR, f'correlation_{var1}_{var2}.png'))\n",
    "            plt.show()\n",
    "    else:\n",
    "        print(\"Não foram encontradas correlações significativas (|r| > 0.5) entre as variáveis.\")\n",
    "\n",
    "# Analisar correlações\n",
    "analyze_correlations(df_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Visualização de Pares de Variáveis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar pares de variáveis numéricas\n",
    "numeric_cols = df_clean.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "\n",
    "# Se houver muitas colunas numéricas, selecionar apenas as mais relevantes\n",
    "if len(numeric_cols) > 5:\n",
    "    # Selecionar as colunas mais relevantes (exemplo: as primeiras 5)\n",
    "    selected_cols = numeric_cols[:5]\n",
    "    print(f\"Selecionando apenas {len(selected_cols)} colunas para visualização de pares: {selected_cols}\")\n",
    "else:\n",
    "    selected_cols = numeric_cols\n",
    "\n",
    "# Criar matriz de gráficos de dispersão\n",
    "plt.figure(figsize=(15, 15))\n",
    "sns.pairplot(df_clean[selected_cols], diag_kind='kde', plot_kws={'alpha': 0.6})\n",
    "plt.suptitle('Matriz de Gráficos de Dispersão', y=1.02, fontsize=16)\n",
    "plt.savefig(os.path.join(IMAGES_DIR, 'pairplot.png'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Análise de Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Pré-processamento de Dados para Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data_for_clustering(df):\n",
    "    \"\"\"\n",
    "    Prepara os dados para análise de clustering.\n",
    "    \n",
    "    Args:\n",
    "        df (pandas.DataFrame): DataFrame a ser processado\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (DataFrame com dados processados, array com features escaladas, lista de nomes de features, objeto scaler)\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"PRÉ-PROCESSAMENTO DE DADOS PARA CLUSTERING\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # Criar uma cópia do DataFrame para não modificar o original\n",
    "    cluster_df = df.copy()\n",
    "    \n",
    "    # Selecionar apenas colunas numéricas para clustering\n",
    "    numeric_cols = df.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "    \n",
    "    # Se 'Yield' estiver nas colunas, removê-la das features (será nossa variável alvo)\n",
    "    feature_names = [col for col in numeric_cols if col.lower() != 'yield']\n",
    "    \n",
    "    print(f\"Features selecionadas para clustering: {feature_names}\")\n",
    "    \n",
    "    # Escalar as features para garantir que todas tenham o mesmo peso\n",
    "    scaler = StandardScaler()\n",
    "    scaled_features = scaler.fit_transform(cluster_df[feature_names])\n",
    "    \n",
    "    print(f\"Dados escalados com StandardScaler. Shape: {scaled_features.shape}\")\n",
    "    \n",
    "    return cluster_df, scaled_features, feature_names, scaler\n",
    "\n",
    "# Pré-processar dados para clustering\n",
    "cluster_df, scaled_features, feature_names, scaler = preprocess_data_for_clustering(df_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Determinação do Número Ótimo de Clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_optimal_clusters(scaled_features, max_clusters=10):\n",
    "    \"\"\"\n",
    "    Determina o número ótimo de clusters usando o método do cotovelo e score de silhueta.\n",
    "    \n",
    "    Args:\n",
    "        scaled_features (numpy.ndarray): Features escaladas\n",
    "        max_clusters (int): Número máximo de clusters a testar\n",
    "        \n",
    "    Returns:\n",
    "        int: Número ótimo de clusters\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"DETERMINAÇÃO DO NÚMERO ÓTIMO DE CLUSTERS\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # Calcular a inércia (soma dos quadrados das distâncias) para diferentes valores de k\n",
    "    inertia = []\n",
    "    silhouette_scores = []\n",
    "    k_values = range(2, max_clusters + 1)\n",
    "    \n",
    "    for k in k_values:\n",
    "        kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "        kmeans.fit(scaled_features)\n",
    "        inertia.append(kmeans.inertia_)\n",
    "        \n",
    "        # Calcular score de silhueta\n",
    "        labels = kmeans.labels_\n",
    "        silhouette_avg = silhouette_score(scaled_features, labels)\n",
    "        silhouette_scores.append(silhouette_avg)\n",
    "        \n",
    "        print(f\"k={k}: Inércia={kmeans.inertia_:.2f}, Score de Silhueta={silhouette_avg:.4f}\")\n",
    "    \n",
    "    # Visualizar o método do cotovelo\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    \n",
    "    # Plot da inércia (método do cotovelo)\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(k_values, inertia, 'o-', color='blue')\n",
    "    plt.xlabel('Número de Clusters (k)')\n",
    "    plt.ylabel('Inércia')\n",
    "    plt.title('Método do Cotovelo')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot do score de silhueta\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(k_values, silhouette_scores, 'o-', color='green')\n",
    "    plt.xlabel('Número de Clusters (k)')\n",
    "    plt.ylabel('Score de Silhueta')\n",
    "    plt.title('Score de Silhueta')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(IMAGES_DIR, 'optimal_clusters.png'))\n",
    "    plt.show()\n",
    "    \n",
    "    # Determinar o número ótimo de clusters\n",
    "    # Baseado no maior score de silhueta\n",
    "    optimal_k = k_values[silhouette_scores.index(max(silhouette_scores))]\n",
    "    \n",
    "    print(f\"\\nNúmero ótimo de clusters (baseado no score de silhueta): {optimal_k}\")\n",
    "    \n",
    "    return optimal_k\n",
    "\n",
    "# Determinar o número ótimo de clusters\n",
    "optimal_k = determine_optimal_clusters(scaled_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Implementação do Algoritmo K-Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_kmeans_clustering(cluster_df, scaled_features, n_clusters, feature_names):\n",
    "    \"\"\"\n",
    "    Realiza o clustering usando o algoritmo K-Means.\n",
    "    \n",
    "    Args:\n",
    "        cluster_df (pandas.DataFrame): DataFrame original\n",
    "        scaled_features (numpy.ndarray): Features escaladas\n",
    "        n_clusters (int): Número de clusters\n",
    "        feature_names (list): Nomes das features usadas para clustering\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (DataFrame com atribuições de cluster, DataFrame com centros dos clusters)\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(f\"CLUSTERING COM K-MEANS (k={n_clusters})\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # Aplicar K-Means com o número ótimo de clusters\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)\n",
    "    cluster_labels = kmeans.fit_predict(scaled_features)\n",
    "    \n",
    "    # Adicionar labels de cluster ao DataFrame original\n",
    "    cluster_df = cluster_df.copy()\n",
    "    cluster_df['Cluster'] = cluster_labels\n",
    "    \n",
    "    # Contar o número de amostras em cada cluster\n",
    "    cluster_counts = cluster_df['Cluster'].value_counts().sort_index()\n",
    "    for cluster, count in cluster_counts.items():\n",
    "        print(f\"Cluster {cluster}: {count} amostras ({count/len(cluster_df)*100:.1f}%)\")\n",
    "    \n",
    "    # Obter os centros dos clusters e convertê-los de volta para a escala original\n",
    "    centers = kmeans.cluster_centers_\n",
    "    \n",
    "    # Criar um DataFrame com os centros dos clusters\n",
    "    centers_df = pd.DataFrame(centers, columns=feature_names)\n",
    "    centers_df.index.name = 'Cluster'\n",
    "    \n",
    "    # Exibir os centros dos clusters\n",
    "    print(\"\\nCentros dos Clusters (features escaladas):\")\n",
    "    display(centers_df)\n",
    "    \n",
    "    return cluster_df, centers_df\n",
    "\n",
    "# Realizar clustering com K-Means\n",
    "cluster_df, centers_df = perform_kmeans_clustering(cluster_df, scaled_features, optimal_k, feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Visualização dos Clusters em 2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_clusters_2d(cluster_df, feature_names):\n",
    "    \"\"\"\n",
    "    Visualiza os clusters em 2D usando as duas primeiras features.\n",
    "    \n",
    "    Args:\n",
    "        cluster_df (pandas.DataFrame): DataFrame com atribuições de cluster\n",
    "        feature_names (list): Nomes das features usadas para clustering\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"VISUALIZAÇÃO DOS CLUSTERS EM 2D\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # Verificar se temos pelo menos 2 features para visualização 2D\n",
    "    if len(feature_names) < 2:\n",
    "        print(\"Não há features suficientes para visualização 2D.\")\n",
    "        return\n",
    "    \n",
    "    # Selecionar as duas primeiras features para visualização\n",
    "    feature1, feature2 = feature_names[0], feature_names[1]\n",
    "    \n",
    "    plt.figure(figsize=(12, 10))\n",
    "    \n",
    "    # Plotar pontos coloridos por cluster\n",
    "    scatter = plt.scatter(cluster_df[feature1], cluster_df[feature2], \n",
    "                c=cluster_df['Cluster'], cmap='viridis', \n",
    "                s=50, alpha=0.7, edgecolors='w')\n",
    "    \n",
    "    # Adicionar legenda\n",
    "    legend1 = plt.legend(*scatter.legend_elements(), title=\"Clusters\")\n",
    "    plt.gca().add_artist(legend1)\n",
    "    \n",
    "    # Adicionar rótulos e título\n",
    "    plt.xlabel(feature1)\n",
    "    plt.ylabel(feature2)\n",
    "    plt.title(f'Visualização dos Clusters: {feature1} vs {feature2}')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Adicionar centros dos clusters\n",
    "    centers = centers_df[[feature1, feature2]].values\n",
    "    plt.scatter(centers[:, 0], centers[:, 1], c='red', marker='X', s=200, alpha=1, label='Centros')\n",
    "    \n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(IMAGES_DIR, 'clusters_2d.png'))\n",
    "    plt.show()\n",
    "    \n",
    "    # Se tivermos mais de 2 features, criar visualizações adicionais com diferentes pares\n",
    "    if len(feature_names) > 2:\n",
    "        print(\"\\nVisualizando clusters com diferentes pares de features:\")\n",
    "        \n",
    "        # Selecionar até 3 pares adicionais de features\n",
    "        pairs = []\n",
    "        for i in range(min(3, len(feature_names) - 1)):\n",
    "            for j in range(i + 1, min(i + 2, len(feature_names))):\n",
    "                if i != 0 or j != 1:  # Evitar repetir o primeiro par\n",
    "                    pairs.append((feature_names[i], feature_names[j]))\n",
    "        \n",
    "        # Plotar cada par adicional\n",
    "        for idx, (feat1, feat2) in enumerate(pairs):\n",
    "            plt.figure(figsize=(10, 8))\n",
    "            \n",
    "            # Plotar pontos coloridos por cluster\n",
    "            scatter = plt.scatter(cluster_df[feat1], cluster_df[feat2], \n",
    "                        c=cluster_df['Cluster'], cmap='viridis', \n",
    "                        s=50, alpha=0.7, edgecolors='w')\n",
    "            \n",
    "            # Adicionar legenda\n",
    "            legend1 = plt.legend(*scatter.legend_elements(), title=\"Clusters\")\n",
    "            plt.gca().add_artist(legend1)\n",
    "            \n",
    "            # Adicionar rótulos e título\n",
    "            plt.xlabel(feat1)\n",
    "            plt.ylabel(feat2)\n",
    "            plt.title(f'Visualização dos Clusters: {feat1} vs {feat2}')\n",
    "            plt.grid(True, alpha=0.3)\n",
    "            \n",
    "            # Adicionar centros dos clusters\n",
    "            centers = centers_df[[feat1, feat2]].values\n",
    "            plt.scatter(centers[:, 0], centers[:, 1], c='red', marker='X', s=200, alpha=1, label='Centros')\n",
    "            \n",
    "            plt.legend()\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(os.path.join(IMAGES_DIR, f'clusters_2d_{idx+1}.png'))\n",
    "            plt.show()\n",
    "\n",
    "# Visualizar clusters em 2D\n",
    "visualize_clusters_2d(cluster_df, feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5 Visualização dos Clusters em 3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_clusters_3d(cluster_df, scaled_features):\n",
    "    \"\"\"\n",
    "    Visualiza os clusters em 3D se houver pelo menos 3 features.\n",
    "    \n",
    "    Args:\n",
    "        cluster_df (pandas.DataFrame): DataFrame com atribuições de cluster\n",
    "        scaled_features (numpy.ndarray): Features escaladas\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"VISUALIZAÇÃO DOS CLUSTERS EM 3D\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # Verificar se temos pelo menos 3 features para visualização 3D\n",
    "    if scaled_features.shape[1] < 3:\n",
    "        print(\"Não há features suficientes para visualização 3D. São necessárias pelo menos 3 features.\")\n",
    "        return\n",
    "    \n",
    "    # Selecionar as três primeiras features para visualização 3D\n",
    "    feature1, feature2, feature3 = feature_names[0], feature_names[1], feature_names[2]\n",
    "    \n",
    "    # Criar figura 3D\n",
    "    fig = plt.figure(figsize=(12, 10))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    \n",
    "    # Plotar pontos 3D coloridos por cluster\n",
    "    scatter = ax.scatter(\n",
    "        cluster_df[feature1], \n",
    "        cluster_df[feature2], \n",
    "        cluster_df[feature3],\n",
    "        c=cluster_df['Cluster'], \n",
    "        cmap='viridis',\n",
    "        s=50, \n",
    "        alpha=0.7\n",
    "    )\n",
    "    \n",
    "    # Adicionar centros dos clusters\n",
    "    centers = centers_df[[feature1, feature2, feature3]].values\n",
    "    ax.scatter(\n",
    "        centers[:, 0], \n",
    "        centers[:, 1], \n",
    "        centers[:, 2],\n",
    "        c='red', \n",
    "        marker='X', \n",
    "        s=200, \n",
    "        alpha=1, \n",
    "        label='Centros'\n",
    "    )\n",
    "    \n",
    "    # Adicionar rótulos e título\n",
    "    ax.set_xlabel(feature1)\n",
    "    ax.set_ylabel(feature2)\n",
    "    ax.set_zlabel(feature3)\n",
    "    ax.set_title(f'Visualização 3D dos Clusters')\n",
    "    \n",
    "    # Adicionar legenda\n",
    "    legend1 = ax.legend(*scatter.legend_elements(), title=\"Clusters\")\n",
    "    ax.add_artist(legend1)\n",
    "    \n",
    "    # Adicionar legenda para os centros\n",
    "    ax.legend([\"Centros\"], loc=\"upper right\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(IMAGES_DIR, 'clusters_3d.png'))\n",
    "    plt.show()\n",
    "\n",
    "# Visualizar clusters em 3D\n",
    "visualize_clusters_3d(cluster_df, scaled_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.6 Identificação de Outliers dentro dos Clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_cluster_outliers(cluster_df, feature_names):\n",
    "    \"\"\"\n",
    "    Identifica outliers dentro de cada cluster usando métodos estatísticos.\n",
    "    \n",
    "    Args:\n",
    "        cluster_df (pandas.DataFrame): DataFrame com atribuições de cluster\n",
    "        feature_names (list): Nomes das features usadas para clustering\n",
    "        \n",
    "    Returns:\n",
    "        pandas.DataFrame: DataFrame com flags de outliers\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"IDENTIFICANDO OUTLIERS DENTRO DOS CLUSTERS\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # Criar uma cópia do DataFrame para adicionar informações de outliers\n",
    "    outlier_df = cluster_df.copy()\n",
    "    outlier_df['is_outlier'] = False\n",
    "    \n",
    "    # Para cada cluster, identificar outliers usando o método IQR\n",
    "    for cluster in sorted(outlier_df['Cluster'].unique()):\n",
    "        cluster_data = outlier_df[outlier_df['Cluster'] == cluster]\n",
    "        \n",
    "        # Calcular outliers para cada feature\n",
    "        for feature in feature_names:\n",
    "            Q1 = cluster_data[feature].quantile(0.25)\n",
    "            Q3 = cluster_data[feature].quantile(0.75)\n",
    "            IQR = Q3 - Q1\n",
    "            \n",
    "            # Definir limites para outliers (1.5 * IQR)\n",
    "            lower_bound = Q1 - 1.5 * IQR\n",
    "            upper_bound = Q3 + 1.5 * IQR\n",
    "            \n",
    "            # Marcar outliers\n",
    "            feature_outliers = (cluster_data[feature] < lower_bound) | (cluster_data[feature] > upper_bound)\n",
    "            outlier_indices = cluster_data[feature_outliers].index\n",
    "            outlier_df.loc[outlier_indices, 'is_outlier'] = True\n",
    "    \n",
    "    # Contar outliers\n",
    "    outlier_count = outlier_df['is_outlier'].sum()\n",
    "    print(f\"Total de outliers identificados: {outlier_count} ({outlier_count/len(outlier_df)*100:.1f}% dos dados)\")\n",
    "    \n",
    "    # Resumir outliers por cluster\n",
    "    print(\"\\nOutliers por cluster:\")\n",
    "    for cluster in sorted(outlier_df['Cluster'].unique()):\n",
    "        cluster_data = outlier_df[outlier_df['Cluster'] == cluster]\n",
    "        cluster_outliers = cluster_data['is_outlier'].sum()\n",
    "        print(f\"Cluster {cluster}: {cluster_outliers} outliers ({cluster_outliers/len(cluster_data)*100:.1f}% do cluster)\")\n",
    "    \n",
    "    # Visualizar outliers em 2D\n",
    "    if len(feature_names) >= 2:\n",
    "        plt.figure(figsize=(12, 10))\n",
    "        \n",
    "        # Plotar pontos normais\n",
    "        non_outliers = outlier_df[~outlier_df['is_outlier']]\n",
    "        plt.scatter(non_outliers[feature_names[0]], non_outliers[feature_names[1]], \n",
    "                    c=non_outliers['Cluster'], cmap='viridis', \n",
    "                    s=50, alpha=0.7, edgecolors='w', label='Normal')\n",
    "        \n",
    "        # Plotar outliers\n",
    "        outliers = outlier_df[outlier_df['is_outlier']]\n",
    "        plt.scatter(outliers[feature_names[0]], outliers[feature_names[1]], \n",
    "                    c=outliers['Cluster'], cmap='viridis', \n",
    "                    s=100, alpha=1.0, edgecolors='red', linewidth=2, marker='X', label='Outlier')\n",
    "        \n",
    "        plt.xlabel(feature_names[0])\n",
    "        plt.ylabel(feature_names[1])\n",
    "        plt.title('Outliers nos Clusters')\n",
    "        plt.legend()\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(IMAGES_DIR, 'cluster_outliers.png'))\n",
    "        plt.show()\n",
    "        print(f\"Visualização de outliers nos clusters salva em '{os.path.join(IMAGES_DIR, 'cluster_outliers.png')}'\")\n",
    "    \n",
    "    # Analisar características dos outliers\n",
    "    if outlier_count > 0:\n",
    "        print(\"\\nCaracterísticas dos outliers:\")\n",
    "        outliers = outlier_df[outlier_df['is_outlier']]\n",
    "        non_outliers = outlier_df[~outlier_df['is_outlier']]\n",
    "        \n",
    "        for feature in feature_names:\n",
    "            outlier_mean = outliers[feature].mean()\n",
    "            non_outlier_mean = non_outliers[feature].mean()\n",
    "            print(f\"{feature}: Média dos outliers = {outlier_mean:.2f}, Média dos não-outliers = {non_outlier_mean:.2f}, Diferença = {outlier_mean - non_outlier_mean:.2f}\")\n",
    "    \n",
    "    return outlier_df\n",
    "\n",
    "# Identificar outliers dentro dos clusters\n",
    "outlier_df = identify_cluster_outliers(cluster_df, feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.7 Resumo dos Resultados do Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_clustering_results(cluster_df, centers_df, feature_names, outlier_df=None):\n",
    "    \"\"\"\n",
    "    Resumo dos resultados do clustering, incluindo características dos clusters e insights.\n",
    "    \n",
    "    Args:\n",
    "        cluster_df (pandas.DataFrame): DataFrame com atribuições de cluster\n",
    "        centers_df (pandas.DataFrame): DataFrame com centros dos clusters\n",
    "        feature_names (list): Nomes das features usadas para clustering\n",
    "        outlier_df (pandas.DataFrame, optional): DataFrame com flags de outliers\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"RESUMO DOS RESULTADOS DO CLUSTERING\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # 1. Informações gerais\n",
    "    n_clusters = len(centers_df)\n",
    "    print(f\"Número de clusters: {n_clusters}\")\n",
    "    print(f\"Número de amostras: {len(cluster_df)}\")\n",
    "    print(f\"Features utilizadas: {', '.join(feature_names)}\")\n",
    "    \n",
    "    # 2. Distribuição de amostras por cluster\n",
    "    print(\"\\nDistribuição de amostras por cluster:\")\n",
    "    cluster_counts = cluster_df['Cluster'].value_counts().sort_index()\n",
    "    \n",
    "    # Criar gráfico de barras para a distribuição de clusters\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    bars = plt.bar(cluster_counts.index, cluster_counts.values, color='skyblue')\n",
    "    \n",
    "    # Adicionar rótulos nas barras\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        plt.text(bar.get_x() + bar.get_width()/2., height + 0.1,\n",
    "                 f'{height} ({height/len(cluster_df)*100:.1f}%)',\n",
    "                 ha='center', va='bottom')\n",
    "    \n",
    "    plt.xlabel('Cluster')\n",
    "    plt.ylabel('Número de Amostras')\n",
    "    plt.title('Distribuição de Amostras por Cluster')\n",
    "    plt.xticks(cluster_counts.index)\n",
    "    plt.grid(axis='y', alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(IMAGES_DIR, 'cluster_distribution.png'))\n",
    "    plt.show()\n",
    "    \n",
    "    # 3. Características de cada cluster\n",
    "    print(\"\\nCaracterísticas de cada cluster (médias):\")\n",
    "    \n",
    "    # Calcular médias para cada feature em cada cluster\n",
    "    cluster_means = cluster_df.groupby('Cluster')[feature_names].mean()\n",
    "    \n",
    "    # Exibir tabela de médias\n",
    "    display(cluster_means)\n",
    "    \n",
    "    # 4. Visualização de radar chart para comparar clusters\n",
    "    print(\"\\nComparando características dos clusters (Radar Chart):\")\n",
    "    \n",
    "    # Normalizar os dados para o radar chart (0-1)\n",
    "    scaler = MinMaxScaler()\n",
    "    cluster_means_scaled = pd.DataFrame(\n",
    "        scaler.fit_transform(cluster_means),\n",
    "        columns=cluster_means.columns,\n",
    "        index=cluster_means.index\n",
    "    )\n",
    "    \n",
    "    # Configurar o radar chart\n",
    "    categories = feature_names\n",
    "    N = len(categories)\n",
    "    \n",
    "    # Calcular os ângulos para cada eixo\n",
    "    angles = [n / float(N) * 2 * np.pi for n in range(N)]\n",
    "    angles += angles[:1]  # Fechar o círculo\n",
    "    \n",
    "    # Criar figura\n",
    "    fig, ax = plt.subplots(figsize=(10, 10), subplot_kw=dict(polar=True))\n",
    "    \n",
    "    # Adicionar cada cluster ao radar chart\n",
    "    for cluster in cluster_means_scaled.index:\n",
    "        values = cluster_means_scaled.loc[cluster].values.tolist()\n",
    "        values += values[:1]  # Fechar o círculo\n",
    "        \n",
    "        # Plotar os valores\n",
    "        ax.plot(angles, values, linewidth=2, linestyle='solid', label=f'Cluster {cluster}')\n",
    "        ax.fill(angles, values, alpha=0.1)\n",
    "    \n",
    "    # Configurar o radar chart\n",
    "    plt.xticks(angles[:-1], categories)\n",
    "    ax.set_rlabel_position(0)\n",
    "    plt.yticks([0, 0.25, 0.5, 0.75, 1], ['0', '0.25', '0.5', '0.75', '1'], color='grey', size=7)\n",
    "    plt.ylim(0, 1)\n",
    "    \n",
    "    # Adicionar legenda e título\n",
    "    plt.legend(loc='upper right', bbox_to_anchor=(0.1, 0.1))\n",
    "    plt.title('Comparação de Características entre Clusters', size=15, y=1.1)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(IMAGES_DIR, 'cluster_radar_chart.png'))\n",
    "    plt.show()\n",
    "    \n",
    "    # 5. Insights e conclusões\n",
    "    print(\"\\nInsights e Conclusões:\")\n",
    "    \n",
    "    # Identificar o cluster com maior produtividade (yield)\n",
    "    if 'yield' in feature_names:\n",
    "        best_cluster = cluster_means['yield'].idxmax()\n",
    "        print(f\"- O Cluster {best_cluster} apresenta a maior produtividade média.\")\n",
    "        \n",
    "        # Identificar as características do melhor cluster\n",
    "        print(\"  Características deste cluster:\")\n",
    "        for feature in feature_names:\n",
    "            if feature != 'yield':\n",
    "                value = cluster_means.loc[best_cluster, feature]\n",
    "                overall_mean = cluster_df[feature].mean()\n",
    "                diff = ((value - overall_mean) / overall_mean) * 100\n",
    "                direction = 'maior' if diff > 0 else 'menor'\n",
    "                print(f\"  - {feature}: {value:.2f} ({abs(diff):.1f}% {direction} que a média geral)\")\n",
    "    \n",
    "    # Verificar relações entre clusters e outliers\n",
    "    if outlier_df is not None and 'is_outlier' in outlier_df.columns:\n",
    "        print(\"\\nRelação entre Clusters e Outliers:\")\n",
    "        outlier_by_cluster = outlier_df.groupby('Cluster')['is_outlier'].mean() * 100\n",
    "        print(f\"- Percentual de outliers por cluster:\")\n",
    "        for cluster, pct in outlier_by_cluster.items():\n",
    "            print(f\"  Cluster {cluster}: {pct:.1f}% de outliers\")\n",
    "        \n",
    "        # Identificar o cluster com maior percentual de outliers\n",
    "        if len(outlier_by_cluster) > 0:\n",
    "            most_outliers_cluster = outlier_by_cluster.idxmax()\n",
    "            print(f\"- O Cluster {most_outliers_cluster} possui o maior percentual de outliers ({outlier_by_cluster[most_outliers_cluster]:.1f}%).\")\n",
    "            print(\"  Isso pode indicar maior variabilidade ou presença de casos atípicos neste grupo.\")\n",
    "    \n",
    "    # 6. Sugestões para análise adicional\n",
    "    print(\"\\nSugestões para Análise Adicional:\")\n",
    "    print(\"- Realizar análise de regressão para cada cluster separadamente para identificar fatores específicos que afetam a produtividade em cada grupo.\")\n",
    "    print(\"- Investigar as condições ambientais e práticas agrícolas associadas a cada cluster para entender melhor as diferenças.\")\n",
    "    print(\"- Considerar a aplicação de técnicas de aprendizado supervisionado para prever a produtividade com base nas características identificadas.\")\n",
    "    print(\"- Explorar a possibilidade de criar recomendações personalizadas para cada grupo de produtores com base nas características do cluster.\")\n",
    "\n",
    "# Resumir os resultados do clustering\n",
    "summarize_clustering_results(cluster_df, centers_df, feature_names, outlier_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Conclusões da Análise de Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nesta análise, aplicamos o algoritmo K-Means para identificar padrões naturais nos dados de produtividade agrícola. Através da análise de clustering, conseguimos identificar grupos distintos de produtores/regiões com características semelhantes.\n",
    "\n",
    "### Principais Descobertas:\n",
    "\n",
    "1. **Identificação de Grupos Distintos**: O algoritmo K-Means identificou grupos com características distintas em termos de variáveis como temperatura, umidade, precipitação e produtividade.\n",
    "\n",
    "2. **Relação entre Variáveis e Produtividade**: Observamos como diferentes combinações de variáveis ambientais estão associadas a níveis distintos de produtividade.\n",
    "\n",
    "3. **Identificação de Outliers**: A análise permitiu identificar casos atípicos dentro de cada cluster, que podem representar condições extremas ou erros de medição.\n",
    "\n",
    "### Implicações Práticas:\n",
    "\n",
    "- **Recomendações Personalizadas**: Com base nos clusters identificados, podemos desenvolver recomendações específicas para cada grupo de produtores.\n",
    "\n",
    "- **Otimização de Recursos**: Entender as características de cada cluster permite alocar recursos de forma mais eficiente, focando em intervenções específicas para cada grupo.\n",
    "\n",
    "- **Previsão de Produtividade**: Os padrões identificados podem ser utilizados para desenvolver modelos preditivos mais precisos para cada grupo.\n",
    "\n",
    "### Próximos Passos:\n",
    "\n",
    "Na próxima etapa deste projeto, iremos desenvolver modelos de aprendizado supervisionado para prever a produtividade com base nas variáveis analisadas. Utilizaremos os insights obtidos na análise de clustering para informar o desenvolvimento desses modelos preditivos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Modelagem Preditiva (Aprendizado Supervisionado)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nesta seção, iremos desenvolver modelos de aprendizado supervisionado para prever a produtividade das culturas com base nas variáveis ambientais e agrícolas. Vamos implementar e comparar cinco modelos diferentes:\n",
    "\n",
    "1. **Regressão Linear**\n",
    "2. **Árvore de Decisão**\n",
    "3. **Random Forest**\n",
    "4. **Gradient Boosting (XGBoost)**\n",
    "5. **Rede Neural (MLP Regressor)**\n",
    "\n",
    "Para cada modelo, vamos avaliar seu desempenho usando métricas como R², MAE, MSE e RMSE, e comparar os resultados para identificar o modelo mais adequado para nosso conjunto de dados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Preparação dos Dados para Modelagem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data_for_modeling(df, target_column='yield', test_size=0.2, random_state=42):\n",
    "    \"\"\"\n",
    "    Prepara os dados para modelagem preditiva, separando features e target,\n",
    "    e dividindo em conjuntos de treino e teste.\n",
    "    \n",
    "    Args:\n",
    "        df (pandas.DataFrame): DataFrame com os dados\n",
    "        target_column (str): Nome da coluna alvo (produtividade)\n",
    "        test_size (float): Proporção dos dados para teste (0.0-1.0)\n",
    "        random_state (int): Semente aleatória para reprodutibilidade\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (X_train, X_test, y_train, y_test, feature_names)\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"PREPARAÇÃO DOS DADOS PARA MODELAGEM PREDITIVA\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # Verificar se a coluna alvo existe no DataFrame\n",
    "    if target_column not in df.columns:\n",
    "        raise ValueError(f\"A coluna alvo '{target_column}' não foi encontrada no DataFrame.\")\n",
    "    \n",
    "    # Remover colunas que não devem ser usadas como features\n",
    "    # Neste caso, se tivermos a coluna 'Cluster' da análise anterior, vamos removê-la\n",
    "    columns_to_drop = ['Cluster', 'is_outlier'] if 'Cluster' in df.columns else []\n",
    "    \n",
    "    # Separar features e target\n",
    "    X = df.drop([target_column] + columns_to_drop, axis=1)\n",
    "    y = df[target_column]\n",
    "    \n",
    "    # Guardar nomes das features para uso posterior\n",
    "    feature_names = X.columns.tolist()\n",
    "    \n",
    "    print(f\"Número total de amostras: {len(df)}\")\n",
    "    print(f\"Número de features: {len(feature_names)}\")\n",
    "    print(f\"Features utilizadas: {', '.join(feature_names)}\")\n",
    "    print(f\"Variável alvo: {target_column}\")\n",
    "    \n",
    "    # Dividir os dados em conjuntos de treino e teste (80% treino, 20% teste)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=test_size, random_state=random_state\n",
    "    )\n",
    "    \n",
    "    print(f\"Tamanho do conjunto de treino: {len(X_train)} amostras ({(1-test_size)*100:.0f}%)\")\n",
    "    print(f\"Tamanho do conjunto de teste: {len(X_test)} amostras ({test_size*100:.0f}%)\")\n",
    "    \n",
    "    # Normalizar os dados\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    print(\"\\nDados normalizados com StandardScaler.\")\n",
    "    \n",
    "    # Verificar distribuição da variável alvo\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.hist(y, bins=20, color='skyblue', edgecolor='black')\n",
    "    plt.title(f'Distribuição da Variável Alvo ({target_column})')\n",
    "    plt.xlabel(target_column)\n",
    "    plt.ylabel('Frequência')\n",
    "    plt.grid(alpha=0.3)\n",
    "    plt.savefig(os.path.join(IMAGES_DIR, 'target_distribution.png'))\n",
    "    plt.show()\n",
    "    \n",
    "    return X_train_scaled, X_test_scaled, y_train, y_test, feature_names, scaler\n",
    "\n",
    "# Preparar dados para modelagem\n",
    "X_train, X_test, y_train, y_test, model_features, scaler = prepare_data_for_modeling(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Funções de Avaliação de Modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_regression_model(model, X_train, X_test, y_train, y_test, model_name):\n",
    "    \"\"\"\n",
    "    Avalia um modelo de regressão usando várias métricas.\n",
    "    \n",
    "    Args:\n",
    "        model: Modelo de regressão treinado\n",
    "        X_train: Features de treino\n",
    "        X_test: Features de teste\n",
    "        y_train: Target de treino\n",
    "        y_test: Target de teste\n",
    "        model_name (str): Nome do modelo para exibição\n",
    "        \n",
    "    Returns:\n",
    "        dict: Dicionário com as métricas de avaliação\n",
    "    \"\"\"\n",
    "    # Fazer predições nos conjuntos de treino e teste\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    \n",
    "    # Calcular métricas de avaliação\n",
    "    train_r2 = r2_score(y_train, y_train_pred)\n",
    "    test_r2 = r2_score(y_test, y_test_pred)\n",
    "    \n",
    "    train_mae = mean_absolute_error(y_train, y_train_pred)\n",
    "    test_mae = mean_absolute_error(y_test, y_test_pred)\n",
    "    \n",
    "    train_mse = mean_squared_error(y_train, y_train_pred)\n",
    "    test_mse = mean_squared_error(y_test, y_test_pred)\n",
    "    \n",
    "    train_rmse = np.sqrt(train_mse)\n",
    "    test_rmse = np.sqrt(test_mse)\n",
    "    \n",
    "    # Exibir resultados\n",
    "    print(f\"\\n{'-'*20} {model_name} {'-'*20}\")\n",
    "    print(f\"R² Score (Treino): {train_r2:.4f}\")\n",
    "    print(f\"R² Score (Teste): {test_r2:.4f}\")\n",
    "    print(f\"MAE (Treino): {train_mae:.4f}\")\n",
    "    print(f\"MAE (Teste): {test_mae:.4f}\")\n",
    "    print(f\"MSE (Treino): {train_mse:.4f}\")\n",
    "    print(f\"MSE (Teste): {test_mse:.4f}\")\n",
    "    print(f\"RMSE (Treino): {train_rmse:.4f}\")\n",
    "    print(f\"RMSE (Teste): {test_rmse:.4f}\")\n",
    "    \n",
    "    # Plotar valores reais vs. previsões\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.scatter(y_test, y_test_pred, alpha=0.7)\n",
    "    \n",
    "    # Adicionar linha de referência (predições perfeitas)\n",
    "    min_val = min(min(y_test), min(y_test_pred))\n",
    "    max_val = max(max(y_test), max(y_test_pred))\n",
    "    plt.plot([min_val, max_val], [min_val, max_val], 'r--')\n",
    "    \n",
    "    plt.xlabel('Valores Reais')\n",
    "    plt.ylabel('Valores Previstos')\n",
    "    plt.title(f'{model_name}: Valores Reais vs. Previstos')\n",
    "    plt.grid(alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(IMAGES_DIR, f'{model_name.lower().replace(\" \", \"_\")}_predictions.png'))\n",
    "    plt.show()\n",
    "    \n",
    "    # Retornar métricas em um dicionário\n",
    "    metrics = {\n",
    "        'model_name': model_name,\n",
    "        'train_r2': train_r2,\n",
    "        'test_r2': test_r2,\n",
    "        'train_mae': train_mae,\n",
    "        'test_mae': test_mae,\n",
    "        'train_mse': train_mse,\n",
    "        'test_mse': test_mse,\n",
    "        'train_rmse': train_rmse,\n",
    "        'test_rmse': test_rmse\n",
    "    }\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "def plot_feature_importance(model, feature_names, model_name):\n",
    "    \"\"\"\n",
    "    Plota a importância das features para modelos que suportam esta funcionalidade.\n",
    "    \n",
    "    Args:\n",
    "        model: Modelo treinado\n",
    "        feature_names (list): Lista com nomes das features\n",
    "        model_name (str): Nome do modelo para exibição\n",
    "    \"\"\"\n",
    "    # Verificar se o modelo suporta feature_importance\n",
    "    if hasattr(model, 'feature_importances_'):\n",
    "        # Obter importância das features\n",
    "        importances = model.feature_importances_\n",
    "        \n",
    "        # Criar DataFrame para facilitar a ordenação\n",
    "        feature_importance_df = pd.DataFrame({\n",
    "            'Feature': feature_names,\n",
    "            'Importance': importances\n",
    "        })\n",
    "        \n",
    "        # Ordenar por importância\n",
    "        feature_importance_df = feature_importance_df.sort_values('Importance', ascending=False)\n",
    "        \n",
    "        # Plotar\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.barh(feature_importance_df['Feature'], feature_importance_df['Importance'])\n",
    "        plt.xlabel('Importância')\n",
    "        plt.ylabel('Feature')\n",
    "        plt.title(f'Importância das Features - {model_name}')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(IMAGES_DIR, f'{model_name.lower().replace(\" \", \"_\")}_feature_importance.png'))\n",
    "        plt.show()\n",
    "        \n",
    "        return feature_importance_df\n",
    "    elif hasattr(model, 'coef_'):\n",
    "        # Para modelos lineares\n",
    "        coefficients = model.coef_\n",
    "        \n",
    "        # Criar DataFrame para facilitar a ordenação\n",
    "        feature_importance_df = pd.DataFrame({\n",
    "            'Feature': feature_names,\n",
    "            'Coefficient': np.abs(coefficients)  # Usar valor absoluto para importância\n",
    "        })\n",
    "        \n",
    "        # Ordenar por importância (valor absoluto do coeficiente)\n",
    "        feature_importance_df = feature_importance_df.sort_values('Coefficient', ascending=False)\n",
    "        \n",
    "        # Plotar\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.barh(feature_importance_df['Feature'], feature_importance_df['Coefficient'])\n",
    "        plt.xlabel('Importância (|Coeficiente|)')\n",
    "        plt.ylabel('Feature')\n",
    "        plt.title(f'Importância das Features - {model_name}')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(IMAGES_DIR, f'{model_name.lower().replace(\" \", \"_\")}_feature_importance.png'))\n",
    "        plt.show()\n",
    "        \n",
    "        return feature_importance_df\n",
    "    else:\n",
    "        print(f\"O modelo {model_name} não suporta visualização de importância de features.\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Preparação dos Dados para Modelagem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparar os dados para modelagem preditiva\n",
    "print(\"=\"*50)\n",
    "print(\"PREPARAÇÃO DOS DADOS PARA MODELAGEM PREDITIVA\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Definir a variável alvo (target) e as features\n",
    "target_column = 'yield'  # Produtividade como variável alvo\n",
    "\n",
    "# Selecionar as features relevantes com base na análise exploratória\n",
    "# Excluir colunas que não são relevantes para a predição\n",
    "feature_columns = [col for col in df.columns if col != target_column]\n",
    "\n",
    "# Criar conjuntos de dados para features e target\n",
    "X = df[feature_columns]\n",
    "y = df[target_column]\n",
    "\n",
    "# Exibir informações sobre os dados\n",
    "print(f\"\\nDimensões do conjunto de features (X): {X.shape}\")\n",
    "print(f\"Dimensões do conjunto alvo (y): {y.shape}\")\n",
    "print(f\"Features utilizadas: {', '.join(feature_columns)}\")\n",
    "\n",
    "# Dividir os dados em conjuntos de treino e teste (80% treino, 20% teste)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"\\nTamanho do conjunto de treino: {X_train.shape[0]} amostras\")\n",
    "print(f\"Tamanho do conjunto de teste: {X_test.shape[0]} amostras\")\n",
    "\n",
    "# Normalizar os dados (opcional, mas recomendado para alguns modelos)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Converter de volta para DataFrame para manter os nomes das colunas\n",
    "X_train = pd.DataFrame(X_train_scaled, columns=feature_columns)\n",
    "X_test = pd.DataFrame(X_test_scaled, columns=feature_columns)\n",
    "\n",
    "# Armazenar os nomes das features para uso posterior\n",
    "model_features = feature_columns\n",
    "\n",
    "print(\"\\nDados preparados com sucesso para modelagem preditiva!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Funções para Avaliação de Modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_regression_model(model, X_train, X_test, y_train, y_test, model_name):\n",
    "    \"\"\"\n",
    "    Avalia um modelo de regressão usando várias métricas.\n",
    "    \n",
    "    Args:\n",
    "        model: Modelo de regressão treinado\n",
    "        X_train: Features do conjunto de treino\n",
    "        X_test: Features do conjunto de teste\n",
    "        y_train: Target do conjunto de treino\n",
    "        y_test: Target do conjunto de teste\n",
    "        model_name: Nome do modelo para exibição\n",
    "    \n",
    "    Returns:\n",
    "        dict: Dicionário com as métricas de avaliação\n",
    "    \"\"\"\n",
    "    # Fazer predições\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    \n",
    "    # Calcular métricas para o conjunto de treino\n",
    "    train_r2 = r2_score(y_train, y_train_pred)\n",
    "    train_mae = mean_absolute_error(y_train, y_train_pred)\n",
    "    train_mse = mean_squared_error(y_train, y_train_pred)\n",
    "    train_rmse = np.sqrt(train_mse)\n",
    "    \n",
    "    # Calcular métricas para o conjunto de teste\n",
    "    test_r2 = r2_score(y_test, y_test_pred)\n",
    "    test_mae = mean_absolute_error(y_test, y_test_pred)\n",
    "    test_mse = mean_squared_error(y_test, y_test_pred)\n",
    "    test_rmse = np.sqrt(test_mse)\n",
    "    \n",
    "    # Exibir resultados\n",
    "    print(f\"\\nResultados para {model_name}:\")\n",
    "    print(\"\\nMétricas no conjunto de treino:\")\n",
    "    print(f\"R² Score: {train_r2:.4f}\")\n",
    "    print(f\"MAE: {train_mae:.4f}\")\n",
    "    print(f\"MSE: {train_mse:.4f}\")\n",
    "    print(f\"RMSE: {train_rmse:.4f}\")\n",
    "    \n",
    "    print(\"\\nMétricas no conjunto de teste:\")\n",
    "    print(f\"R² Score: {test_r2:.4f}\")\n",
    "    print(f\"MAE: {test_mae:.4f}\")\n",
    "    print(f\"MSE: {test_mse:.4f}\")\n",
    "    print(f\"RMSE: {test_rmse:.4f}\")\n",
    "    \n",
    "    # Visualizar predições vs valores reais\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    \n",
    "    # Gráfico para o conjunto de treino\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.scatter(y_train, y_train_pred, alpha=0.5)\n",
    "    plt.plot([y_train.min(), y_train.max()], [y_train.min(), y_train.max()], 'r--')\n",
    "    plt.title(f'Valores Reais vs. Previsões (Treino)\nR² = {train_r2:.4f}')\n",
    "    plt.xlabel('Valores Reais')\n",
    "    plt.ylabel('Previsões')\n",
    "    \n",
    "    # Gráfico para o conjunto de teste\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.scatter(y_test, y_test_pred, alpha=0.5)\n",
    "    plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')\n",
    "    plt.title(f'Valores Reais vs. Previsões (Teste)\nR² = {test_r2:.4f}')\n",
    "    plt.xlabel('Valores Reais')\n",
    "    plt.ylabel('Previsões')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(IMAGES_DIR, f'model_predictions_{model_name.replace(\" \", \"_\").lower()}.png'))\n",
    "    plt.show()\n",
    "    \n",
    "    # Retornar métricas em um dicionário\n",
    "    return {\n",
    "        'model_name': model_name,\n",
    "        'train_r2': train_r2,\n",
    "        'train_mae': train_mae,\n",
    "        'train_mse': train_mse,\n",
    "        'train_rmse': train_rmse,\n",
    "        'test_r2': test_r2,\n",
    "        'test_mae': test_mae,\n",
    "        'test_mse': test_mse,\n",
    "        'test_rmse': test_rmse\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_feature_importance(model, feature_names, model_name):\n",
    "    \"\"\"\n",
    "    Plota a importância das features para um modelo.\n",
    "    \n",
    "    Args:\n",
    "        model: Modelo treinado\n",
    "        feature_names: Lista com os nomes das features\n",
    "        model_name: Nome do modelo para exibição\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame: DataFrame com a importância das features\n",
    "    \"\"\"\n",
    "    # Verificar se o modelo tem atributo de importância de features\n",
    "    if hasattr(model, 'feature_importances_'):\n",
    "        # Para modelos baseados em árvores\n",
    "        importances = model.feature_importances_\n",
    "    elif hasattr(model, 'coef_'):\n",
    "        # Para modelos lineares\n",
    "        coefficients = model.coef_\n",
    "        \n",
    "        # Criar DataFrame para facilitar a ordenação\n",
    "        importances = np.abs(coefficients)  # Usar valor absoluto para importância\n",
    "    else:\n",
    "        print(f\"O modelo {model_name} não suporta visualização de importância de features.\")\n",
    "        return None\n",
    "    \n",
    "    # Criar DataFrame com importâncias\n",
    "    importance_df = pd.DataFrame({\n",
    "        'Feature': feature_names,\n",
    "        'Importance': importances\n",
    "    })\n",
    "    \n",
    "    # Ordenar por importância\n",
    "    importance_df = importance_df.sort_values('Importance', ascending=False).reset_index(drop=True)\n",
    "    \n",
    "    # Plotar\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.barplot(x='Importance', y='Feature', data=importance_df)\n",
    "    plt.title(f'Importância das Features - {model_name}')\n",
    "    plt.xlabel('Importância')\n",
    "    plt.ylabel('Feature')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(IMAGES_DIR, f'feature_importance_{model_name.replace(\" \", \"_\").lower()}.png'))\n",
    "    plt.show()\n",
    "    \n",
    "    # Exibir tabela de importância\n",
    "    print(f\"\\nImportância das Features - {model_name}:\")\n",
    "    display(importance_df)\n",
    "    \n",
    "    return importance_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 Implementação e Avaliação dos Modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.3.1 Regressão Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementar e avaliar o modelo de Regressão Linear\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"MODELO 1: REGRESSÃO LINEAR\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Criar e treinar o modelo\n",
    "lr_model = LinearRegression()\n",
    "lr_model.fit(X_train, y_train)\n",
    "\n",
    "# Avaliar o modelo\n",
    "lr_metrics = evaluate_regression_model(lr_model, X_train, X_test, y_train, y_test, \"Regressão Linear\")\n",
    "\n",
    "# Visualizar importância das features\n",
    "lr_importance = plot_feature_importance(lr_model, model_features, \"Regressão Linear\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.3.2 Árvore de Decisão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementar e avaliar o modelo de Árvore de Decisão\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"MODELO 2: ÁRVORE DE DECISÃO\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Criar e treinar o modelo\n",
    "dt_model = DecisionTreeRegressor(random_state=42)\n",
    "dt_model.fit(X_train, y_train)\n",
    "\n",
    "# Avaliar o modelo\n",
    "dt_metrics = evaluate_regression_model(dt_model, X_train, X_test, y_train, y_test, \"Árvore de Decisão\")\n",
    "\n",
    "# Visualizar importância das features\n",
    "dt_importance = plot_feature_importance(dt_model, model_features, \"Árvore de Decisão\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.3.3 Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementar e avaliar o modelo Random Forest\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"MODELO 3: RANDOM FOREST\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Criar e treinar o modelo\n",
    "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Avaliar o modelo\n",
    "rf_metrics = evaluate_regression_model(rf_model, X_train, X_test, y_train, y_test, \"Random Forest\")\n",
    "\n",
    "# Visualizar importância das features\n",
    "rf_importance = plot_feature_importance(rf_model, model_features, \"Random Forest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.3.4 Gradient Boosting (XGBoost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementar e avaliar o modelo XGBoost\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"MODELO 4: XGBOOST\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Criar e treinar o modelo\n",
    "xgb_model = XGBRegressor(n_estimators=100, learning_rate=0.1, random_state=42)\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Avaliar o modelo\n",
    "xgb_metrics = evaluate_regression_model(xgb_model, X_train, X_test, y_train, y_test, \"XGBoost\")\n",
    "\n",
    "# Visualizar importância das features\n",
    "xgb_importance = plot_feature_importance(xgb_model, model_features, \"XGBoost\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.3.5 Rede Neural (MLP Regressor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementar e avaliar o modelo de Rede Neural\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"MODELO 5: REDE NEURAL (MLP REGRESSOR)\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Criar e treinar o modelo\n",
    "mlp_model = MLPRegressor(hidden_layer_sizes=(100, 50), activation='relu', \n",
    "                        max_iter=1000, random_state=42)\n",
    "mlp_model.fit(X_train, y_train)\n",
    "\n",
    "# Avaliar o modelo\n",
    "mlp_metrics = evaluate_regression_model(mlp_model, X_train, X_test, y_train, y_test, \"MLP Regressor\")\n",
    "\n",
    "# O MLP não tem atributo de importância de features, então não podemos visualizar\n",
    "print(\"\\nNota: O modelo MLP Regressor não suporta visualização de importância de features.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.4 Comparação dos Modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_models(metrics_list):\n",
    "    \"\"\"\n",
    "    Compara os modelos com base nas métricas de avaliação.\n",
    "    \n",
    "    Args:\n",
    "        metrics_list (list): Lista de dicionários com métricas de cada modelo\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"COMPARAÇÃO DOS MODELOS\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # Criar DataFrame com as métricas de cada modelo\n",
    "    comparison_df = pd.DataFrame(metrics_list)\n",
    "    comparison_df = comparison_df.set_index('model_name')\n",
    "    \n",
    "    # Exibir tabela de comparação\n",
    "    print(\"\\nTabela de Comparação de Métricas:\")\n",
    "    display(comparison_df)\n",
    "    \n",
    "    # Identificar o melhor modelo com base no R² do conjunto de teste\n",
    "    best_model_idx = comparison_df['test_r2'].idxmax()\n",
    "    best_r2 = comparison_df.loc[best_model_idx, 'test_r2']\n",
    "    print(f\"\\nMelhor modelo (R² no teste): {best_model_idx} (R² = {best_r2:.4f})\")\n",
    "    \n",
    "    # Identificar o melhor modelo com base no RMSE do conjunto de teste\n",
    "    best_rmse_idx = comparison_df['test_rmse'].idxmin()\n",
    "    best_rmse = comparison_df.loc[best_rmse_idx, 'test_rmse']\n",
    "    print(f\"Melhor modelo (RMSE no teste): {best_rmse_idx} (RMSE = {best_rmse:.4f})\")\n",
    "    \n",
    "    # Visualizar comparação de R²\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    # Extrair nomes dos modelos e valores de R²\n",
    "    model_names = comparison_df.index\n",
    "    train_r2 = comparison_df['train_r2']\n",
    "    test_r2 = comparison_df['test_r2']\n",
    "    \n",
    "    # Configurar barras\n",
    "    x = np.arange(len(model_names))\n",
    "    width = 0.35\n",
    "    \n",
    "    # Plotar barras\n",
    "    plt.bar(x - width/2, train_r2, width, label='Treino')\n",
    "    plt.bar(x + width/2, test_r2, width, label='Teste')\n",
    "    \n",
    "    # Adicionar rótulos e título\n",
    "    plt.xlabel('Modelo')\n",
    "    plt.ylabel('R² Score')\n",
    "    plt.title('Comparação de R² Score entre Modelos')\n",
    "    plt.xticks(x, model_names, rotation=45)\n",
    "    plt.ylim(0, 1)  # R² geralmente varia de 0 a 1\n",
    "    plt.legend()\n",
    "    plt.grid(axis='y', alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(IMAGES_DIR, 'model_r2_comparison.png'))\n",
    "    plt.show()\n",
    "    \n",
    "    # Visualizar comparação de RMSE\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    # Extrair valores de RMSE\n",
    "    train_rmse = comparison_df['train_rmse']\n",
    "    test_rmse = comparison_df['test_rmse']\n",
    "    \n",
    "    # Plotar barras\n",
    "    plt.bar(x - width/2, train_rmse, width, label='Treino')\n",
    "    plt.bar(x + width/2, test_rmse, width, label='Teste')\n",
    "    \n",
    "    # Adicionar rótulos e título\n",
    "    plt.xlabel('Modelo')\n",
    "    plt.ylabel('RMSE')\n",
    "    plt.title('Comparação de RMSE entre Modelos')\n",
    "    plt.xticks(x, model_names, rotation=45)\n",
    "    plt.legend()\n",
    "    plt.grid(axis='y', alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(IMAGES_DIR, 'model_rmse_comparison.png'))\n",
    "    plt.show()\n",
    "    \n",
    "    # Verificar overfitting\n",
    "    print(\"\\nVerificação de Overfitting:\")\n",
    "    for model in model_names:\n",
    "        train_test_diff = comparison_df.loc[model, 'train_r2'] - comparison_df.loc[model, 'test_r2']\n",
    "        if train_test_diff > 0.1:\n",
    "            print(f\"- {model}: Possível overfitting (diferença de R² entre treino e teste: {train_test_diff:.4f})\")\n",
    "        else:\n",
    "            print(f\"- {model}: Sem sinais claros de overfitting (diferença de R²: {train_test_diff:.4f})\")\n",
    "    \n",
    "    # Conclusão e recomendações\n",
    "    print(\"\\nCONCLUSÃO:\")\n",
    "    print(f\"Com base nas métricas de avaliação, o modelo {best_model_idx} apresentou o melhor desempenho geral.\")\n",
    "    \n",
    "    # Verificar se o melhor modelo tem overfitting\n",
    "    best_model_diff = comparison_df.loc[best_model_idx, 'train_r2'] - comparison_df.loc[best_model_idx, 'test_r2']\n",
    "    if best_model_diff > 0.1:\n",
    "        print(f\"No entanto, este modelo apresenta sinais de overfitting. Recomenda-se ajustar hiperparâmetros ou usar técnicas de regularização.\")\n",
    "    \n",
    "    return comparison_df\n",
    "\n",
    "# Comparar todos os modelos\n",
    "all_metrics = [lr_metrics, dt_metrics, rf_metrics, xgb_metrics, mlp_metrics]\n",
    "model_comparison = compare_models(all_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Conclusões e Próximos Passos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1 Resumo dos Resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neste projeto, realizamos uma análise completa de dados de produtividade agrícola, incluindo:\n",
    "\n",
    "1. **Análise Exploratória de Dados**:\n",
    "   - Identificamos as principais características do conjunto de dados\n",
    "   - Analisamos a distribuição das variáveis\n",
    "   - Verificamos a presença de valores ausentes e outliers\n",
    "\n",
    "2. **Análise de Correlação**:\n",
    "   - Identificamos as variáveis mais correlacionadas com a produtividade\n",
    "   - Visualizamos as relações entre as variáveis através de matrizes de correlação e pairplots\n",
    "\n",
    "3. **Análise de Clustering**:\n",
    "   - Aplicamos o algoritmo K-Means para identificar grupos naturais nos dados\n",
    "   - Determinamos o número ótimo de clusters usando o método do cotovelo e score de silhueta\n",
    "   - Visualizamos os clusters em 2D e 3D\n",
    "   - Identificamos outliers dentro dos clusters\n",
    "\n",
    "4. **Modelagem Preditiva**:\n",
    "   - Implementamos cinco modelos de aprendizado supervisionado\n",
    "   - Avaliamos o desempenho dos modelos usando métricas como R², MAE, MSE e RMSE\n",
    "   - Identificamos o modelo com melhor desempenho para prever a produtividade\n",
    "\n",
    "Os resultados obtidos fornecem insights valiosos sobre os fatores que influenciam a produtividade agrícola e como podemos prever a produtividade com base nesses fatores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2 Próximos Passos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com base nos resultados obtidos, sugerimos os seguintes próximos passos:\n",
    "\n",
    "1. **Otimização de Hiperparâmetros**:\n",
    "   - Realizar uma busca mais exaustiva de hiperparâmetros para o modelo com melhor desempenho\n",
    "   - Utilizar técnicas como Grid Search ou Random Search para encontrar a configuração ótima\n",
    "\n",
    "2. **Feature Engineering**:\n",
    "   - Criar novas features que possam capturar relações não lineares entre as variáveis\n",
    "   - Explorar transformações de variáveis para melhorar o desempenho dos modelos\n",
    "\n",
    "3. **Validação Cruzada**:\n",
    "   - Implementar validação cruzada para obter uma avaliação mais robusta dos modelos\n",
    "   - Testar a estabilidade dos modelos em diferentes subconjuntos dos dados\n",
    "\n",
    "4. **Explicação do Modelo**:\n",
    "   - Utilizar técnicas como SHAP (SHapley Additive exPlanations) para interpretar as predições do modelo\n",
    "   - Fornecer explicações claras sobre como cada variável influencia a produtividade\n",
    "\n",
    "5. **Implementação Prática**:\n",
    "   - Desenvolver uma aplicação ou dashboard para que agricultores possam utilizar o modelo para prever a produtividade\n",
    "   - Integrar o modelo com sistemas de monitoramento agrícola para fornecer recomendações em tempo real\n",
    "\n",
    "Estes próximos passos permitirão aprimorar ainda mais a análise e tornar os resultados mais úteis para aplicações práticas no setor agrícola."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
